#!/usr/bin/env python3
"""
Database management for translation auditing and queries.

Architecture:
- locales/content/{locale}/*.json - Version-controlled source of truth (flat keys)
- locales/db/tasks.db - Working database for translation workflows
- locales/db/schema.sql - Table definitions

Tables:
- translation_tasks: Generated by tasks/create.py for translation workflows
- glossary: Terminology decisions per locale (committable via SQL export)
- session_log: Translation session records (committable via SQL export)
- translation_issues: QC findings requiring review (committable via SQL export)

Usage:
    python store.py init                          # Create database from schema
    python store.py migrate                       # Apply schema updates
    python store.py query "SELECT ..." [--json]   # Run SQL query
    python store.py export [TABLE]                # Export committable tables to SQL
    python store.py import [FILE]                 # Import SQL file into database
"""

import argparse
import hashlib
import json
import sqlite3
import sys
from contextlib import contextmanager
from pathlib import Path
from typing import Any, Iterator, Optional

# Path constants relative to script location
SCRIPT_DIR = Path(__file__).parent.resolve()
LOCALES_DIR = SCRIPT_DIR.parent
DB_DIR = LOCALES_DIR / "db"
SCHEMA_FILE = DB_DIR / "schema.sql"
DB_FILE = DB_DIR / "tasks.db"

# Tables that can be exported/imported for version control
COMMITTABLE_TABLES = ["glossary", "session_log", "translation_issues"]


@contextmanager
def get_connection() -> Iterator[sqlite3.Connection]:
    """Context manager for database connections.

    Abstracts connection handling for future migration to libsql.
    """
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


# Schema versions - add new entries when schema changes
SCHEMA_VERSIONS = [
    ("001", "initial_tables"),
    ("002", "translation_tasks"),
    ("003", "glossary"),
    ("004", "session_log"),
    ("005", "source_status"),
    ("006", "rename_columns"),
    ("007", "translation_issues"),
]


def init_database(force: bool = False) -> None:
    """Initialize database from schema.sql.

    Creates a fresh database with all tables defined in schema.sql.

    Args:
        force: If True, delete existing database and recreate.
    """
    if not SCHEMA_FILE.exists():
        raise FileNotFoundError(f"Schema file not found: {SCHEMA_FILE}")

    if DB_FILE.exists():
        if force:
            DB_FILE.unlink()
            print(f"Removed existing database: {DB_FILE}")
        else:
            print(f"Database already exists: {DB_FILE}")
            print("Use --force to recreate.")
            return

    # Ensure db directory exists
    DB_DIR.mkdir(parents=True, exist_ok=True)

    schema_sql = SCHEMA_FILE.read_text(encoding="utf-8")

    with get_connection() as conn:
        cursor = conn.cursor()
        try:
            cursor.executescript(schema_sql)
            conn.commit()
        except sqlite3.Error as e:
            raise RuntimeError(f"SQL error during schema creation: {e}") from e

    print(f"Created database: {DB_FILE}")


def migrate_schema() -> None:
    """Apply schema updates to existing database.

    Runs schema.sql which uses CREATE TABLE IF NOT EXISTS,
    so it safely adds new tables without affecting existing ones.
    Tracks applied migrations in schema_migrations table.
    """
    if not SCHEMA_FILE.exists():
        raise FileNotFoundError(f"Schema file not found: {SCHEMA_FILE}")

    if not DB_FILE.exists():
        print(f"Database does not exist: {DB_FILE}")
        print("Use 'python store.py init' to create it first.")
        return

    schema = SCHEMA_FILE.read_text(encoding="utf-8")

    with get_connection() as conn:
        # Apply schema (idempotent due to IF NOT EXISTS)
        conn.executescript(schema)

        # Check which versions are already recorded
        cursor = conn.cursor()
        cursor.execute("SELECT version FROM schema_migrations")
        applied = {row[0] for row in cursor.fetchall()}

        # Record any missing versions
        new_versions = []
        for version, name in SCHEMA_VERSIONS:
            if version not in applied:
                cursor.execute(
                    "INSERT INTO schema_migrations (version, name) VALUES (?, ?)",
                    (version, name),
                )
                new_versions.append(f"{version}_{name}")

        conn.commit()

    print(f"Schema applied to: {DB_FILE}")
    if new_versions:
        print(f"New migrations recorded: {', '.join(new_versions)}")
    else:
        print("Schema is up to date.")


def _load_checksums() -> dict[str, str]:
    """Load checksums from checksums.sha256 file.

    Returns:
        Dictionary mapping filename to expected SHA256 hash.
        Empty dict if checksums file doesn't exist.
    """
    checksum_file = DB_DIR / "checksums.sha256"
    checksums: dict[str, str] = {}

    if not checksum_file.exists():
        return checksums

    for line in checksum_file.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line:
            continue
        # Format: "hash  filename" (two spaces, standard sha256sum format)
        parts = line.split("  ", 1)
        if len(parts) == 2:
            hash_hex, filename = parts
            checksums[filename] = hash_hex

    return checksums


def query(
    sql: str,
    params: Optional[tuple] = None,
    output_json: bool = False,
) -> list[dict[str, Any]]:
    """Run a SQL query and return results.

    Args:
        sql: SQL query string.
        params: Optional tuple of query parameters.
        output_json: If True, output JSON format.

    Returns:
        List of row dictionaries.
    """
    if not DB_FILE.exists():
        raise FileNotFoundError(
            f"Database not found: {DB_FILE}\n"
            "Run 'python store.py init' to create it."
        )

    with get_connection() as conn:
        cursor = conn.cursor()
        try:
            if params:
                cursor.execute(sql, params)
            else:
                cursor.execute(sql)

            # Check if this is a SELECT query
            if cursor.description is None:
                conn.commit()
                print(f"Query executed. Rows affected: {cursor.rowcount}")
                return []

            rows = cursor.fetchall()
            results = [dict(row) for row in rows]

            if output_json:
                print(json.dumps(results, indent=2, default=str))
            else:
                _print_table(results, cursor.description)

            return results

        except sqlite3.Error as e:
            raise RuntimeError(f"SQL error: {e}") from e


def export_tables(table: Optional[str] = None) -> None:
    """Export committable tables to SQL files.

    Exports data as INSERT statements that can be committed to git.
    Files are written to locales/db/{table}.sql.

    Args:
        table: Specific table to export, or None for all committable tables.
    """
    if not DB_FILE.exists():
        raise FileNotFoundError(
            f"Database not found: {DB_FILE}\n"
            "Run 'python store.py init' to create it."
        )

    tables_to_export = [table] if table else COMMITTABLE_TABLES

    for tbl in tables_to_export:
        if tbl not in COMMITTABLE_TABLES:
            print(f"Warning: '{tbl}' is not a committable table. Skipping.")
            continue

        output_file = DB_DIR / f"{tbl}.sql"

        with get_connection() as conn:
            cursor = conn.cursor()

            # Get row count
            cursor.execute(f"SELECT COUNT(*) FROM {tbl}")  # noqa: S608
            count = cursor.fetchone()[0]

            if count == 0:
                print(f"{tbl}: empty (skipping)")
                continue

            # Get column names
            cursor.execute(f"PRAGMA table_info({tbl})")  # noqa: S608
            columns = [row[1] for row in cursor.fetchall()]

            # Build INSERT statements
            cursor.execute(f"SELECT * FROM {tbl}")  # noqa: S608
            rows = cursor.fetchall()

            lines = [
                f"-- Exported from {tbl} table",
                f"-- {count} rows",
                f"-- Generated: {__import__('datetime').datetime.now().isoformat()}",
                "",
                f"DELETE FROM {tbl};",
                "",
            ]

            for row in rows:
                values = []
                for val in row:
                    if val is None:
                        values.append("NULL")
                    elif isinstance(val, (int, float)):
                        values.append(str(val))
                    else:
                        # Escape single quotes
                        escaped = str(val).replace("'", "''")
                        values.append(f"'{escaped}'")

                cols_str = ", ".join(columns)
                vals_str = ", ".join(values)
                lines.append(f"INSERT INTO {tbl} ({cols_str}) VALUES ({vals_str});")

            output_file.write_text("\n".join(lines) + "\n", encoding="utf-8")
            print(f"{tbl}: exported {count} rows to {output_file.name}")

    # Generate checksums for exported files
    _generate_checksums()


def _generate_checksums() -> None:
    """Generate checksums.sha256 for all committable table SQL files."""
    checksum_file = DB_DIR / "checksums.sha256"
    lines = []

    for tbl in COMMITTABLE_TABLES:
        sql_file = DB_DIR / f"{tbl}.sql"
        if sql_file.exists():
            content = sql_file.read_bytes()
            hash_hex = hashlib.sha256(content).hexdigest()
            lines.append(f"{hash_hex}  {tbl}.sql")

    if lines:
        checksum_file.write_text("\n".join(lines) + "\n", encoding="utf-8")
        print(f"checksums.sha256: updated")


def import_tables(file_path: Optional[str] = None, verify: bool = True) -> None:
    """Import SQL files into database.

    Imports data from SQL files in locales/db/.

    Args:
        file_path: Specific file to import, or None for all committable table files.
        verify: If True, verify checksums before importing.
    """
    if not DB_FILE.exists():
        raise FileNotFoundError(
            f"Database not found: {DB_FILE}\n"
            "Run 'python store.py init' to create it."
        )

    if file_path:
        files_to_import = [Path(file_path)]
    else:
        files_to_import = [
            DB_DIR / f"{tbl}.sql"
            for tbl in COMMITTABLE_TABLES
            if (DB_DIR / f"{tbl}.sql").exists()
        ]

    if not files_to_import:
        print("No SQL files found to import.")
        return

    # Load checksums if verification enabled
    checksums = _load_checksums() if verify else {}

    with get_connection() as conn:
        for sql_file in files_to_import:
            if not sql_file.exists():
                print(f"Warning: {sql_file} not found. Skipping.")
                continue

            content = sql_file.read_bytes()

            # Verify checksum if available
            if verify and checksums:
                expected = checksums.get(sql_file.name)
                if expected:
                    actual = hashlib.sha256(content).hexdigest()
                    if actual != expected:
                        print(
                            f"Warning: Checksum mismatch for {sql_file.name}, "
                            "skipping import",
                            file=sys.stderr,
                        )
                        continue

            sql_content = content.decode("utf-8")

            try:
                conn.executescript(sql_content)
                conn.commit()

                # Count rows in affected table
                table_name = sql_file.stem
                if table_name in COMMITTABLE_TABLES:
                    cursor = conn.cursor()
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")  # noqa: S608
                    count = cursor.fetchone()[0]
                    print(f"{sql_file.name}: imported ({count} rows in {table_name})")
                else:
                    print(f"{sql_file.name}: imported")

            except sqlite3.Error as e:
                print(f"Error importing {sql_file.name}: {e}", file=sys.stderr)


def _print_table(rows: list[dict], description: tuple) -> None:
    """Print results as a human-readable table."""
    if not rows:
        print("No results.")
        return

    # Get column names
    columns = [col[0] for col in description]

    # Calculate column widths
    widths = {col: len(col) for col in columns}
    for row in rows:
        for col in columns:
            val = str(row.get(col, ""))
            # Truncate long values for display
            if len(val) > 50:
                val = val[:47] + "..."
            widths[col] = max(widths[col], len(val))

    # Print header
    header = " | ".join(col.ljust(widths[col]) for col in columns)
    separator = "-+-".join("-" * widths[col] for col in columns)
    print(header)
    print(separator)

    # Print rows
    for row in rows:
        line_parts = []
        for col in columns:
            val = str(row.get(col, ""))
            if len(val) > 50:
                val = val[:47] + "..."
            line_parts.append(val.ljust(widths[col]))
        print(" | ".join(line_parts))

    print(f"\n({len(rows)} rows)")


def main() -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Database management for translation auditing.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python store.py init                    # Create database from schema
    python store.py init --force            # Recreate database
    python store.py migrate                 # Apply schema updates
    python store.py query "SELECT * FROM glossary"
    python store.py query --json "SELECT * FROM session_log"
    python store.py export                  # Export all committable tables
    python store.py export glossary         # Export specific table
    python store.py import                  # Import all SQL files
    python store.py import glossary.sql     # Import specific file
        """,
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    # init subcommand
    init_parser = subparsers.add_parser(
        "init", help="Create database from schema.sql"
    )
    init_parser.add_argument(
        "--force",
        "-f",
        action="store_true",
        help="Delete existing database and recreate",
    )

    # migrate subcommand
    subparsers.add_parser(
        "migrate", help="Apply schema updates to existing database"
    )

    # query subcommand
    query_parser = subparsers.add_parser("query", help="Run a SQL query")
    query_parser.add_argument("sql", help="SQL query to execute")
    query_parser.add_argument(
        "--json", "-j", action="store_true", help="Output results as JSON"
    )

    # export subcommand
    export_parser = subparsers.add_parser(
        "export", help="Export committable tables to SQL files"
    )
    export_parser.add_argument(
        "table",
        nargs="?",
        choices=COMMITTABLE_TABLES,
        help=f"Table to export (default: all of {', '.join(COMMITTABLE_TABLES)})",
    )

    # import subcommand
    import_parser = subparsers.add_parser(
        "import", help="Import SQL files into database"
    )
    import_parser.add_argument(
        "file",
        nargs="?",
        help="SQL file to import (default: all committable table files)",
    )
    import_parser.add_argument(
        "--no-verify",
        action="store_true",
        help="Skip checksum verification",
    )

    args = parser.parse_args()

    try:
        if args.command == "init":
            init_database(force=args.force)
        elif args.command == "migrate":
            migrate_schema()
        elif args.command == "query":
            query(
                args.sql,
                output_json=args.json,
            )
        elif args.command == "export":
            export_tables(table=args.table)
        elif args.command == "import":
            import_tables(file_path=args.file, verify=not args.no_verify)
    except FileNotFoundError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except RuntimeError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
