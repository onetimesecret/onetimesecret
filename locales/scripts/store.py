#!/usr/bin/env python3
"""
Database management for translation auditing and queries.

Architecture:
- locales/content/{locale}/*.json - Version-controlled source of truth (flat keys)
- locales/db/tasks.db - Working database for translation workflows
- locales/db/schema.sql - Table definitions

Tables:
- translation_tasks: Generated by tasks/create.py for translation workflows
- glossary: Terminology decisions per locale (committable via SQL export)
- session_log: Translation session records (committable via SQL export)
- translation_issues: QC findings requiring review (committable via SQL export)

Usage:
    python store.py init                          # Create database from schema
    python store.py migrate                       # Apply schema updates
    python store.py query "SELECT ..." [--json]   # Run SQL query
"""

import argparse
import json
import sqlite3
import sys
from contextlib import contextmanager
from pathlib import Path
from typing import Any, Iterator, Optional

# Path constants relative to script location
SCRIPT_DIR = Path(__file__).parent.resolve()
LOCALES_DIR = SCRIPT_DIR.parent
DB_DIR = LOCALES_DIR / "db"
SCHEMA_FILE = DB_DIR / "schema.sql"
DB_FILE = DB_DIR / "tasks.db"


@contextmanager
def get_connection() -> Iterator[sqlite3.Connection]:
    """Context manager for database connections.

    Abstracts connection handling for future migration to libsql.
    """
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


# Schema versions - add new entries when schema changes
SCHEMA_VERSIONS = [
    ("001", "initial_tables"),
    ("002", "translation_tasks"),
    ("003", "glossary"),
    ("004", "session_log"),
    ("005", "source_status"),
    ("006", "rename_columns"),
    ("007", "translation_issues"),
]


def init_database(force: bool = False) -> None:
    """Initialize database from schema.sql.

    Creates a fresh database with all tables defined in schema.sql.

    Args:
        force: If True, delete existing database and recreate.
    """
    if not SCHEMA_FILE.exists():
        raise FileNotFoundError(f"Schema file not found: {SCHEMA_FILE}")

    if DB_FILE.exists():
        if force:
            DB_FILE.unlink()
            print(f"Removed existing database: {DB_FILE}")
        else:
            print(f"Database already exists: {DB_FILE}")
            print("Use --force to recreate.")
            return

    # Ensure db directory exists
    DB_DIR.mkdir(parents=True, exist_ok=True)

    schema_sql = SCHEMA_FILE.read_text(encoding="utf-8")

    with get_connection() as conn:
        cursor = conn.cursor()
        try:
            cursor.executescript(schema_sql)
            conn.commit()
        except sqlite3.Error as e:
            raise RuntimeError(f"SQL error during schema creation: {e}") from e

    print(f"Created database: {DB_FILE}")


def migrate_schema() -> None:
    """Apply schema updates to existing database.

    Runs schema.sql which uses CREATE TABLE IF NOT EXISTS,
    so it safely adds new tables without affecting existing ones.
    Tracks applied migrations in schema_migrations table.
    """
    if not SCHEMA_FILE.exists():
        raise FileNotFoundError(f"Schema file not found: {SCHEMA_FILE}")

    if not DB_FILE.exists():
        print(f"Database does not exist: {DB_FILE}")
        print("Use 'python store.py init' to create it first.")
        return

    schema = SCHEMA_FILE.read_text(encoding="utf-8")

    with get_connection() as conn:
        # Apply schema (idempotent due to IF NOT EXISTS)
        conn.executescript(schema)

        # Check which versions are already recorded
        cursor = conn.cursor()
        cursor.execute("SELECT version FROM schema_migrations")
        applied = {row[0] for row in cursor.fetchall()}

        # Record any missing versions
        new_versions = []
        for version, name in SCHEMA_VERSIONS:
            if version not in applied:
                cursor.execute(
                    "INSERT INTO schema_migrations (version, name) VALUES (?, ?)",
                    (version, name),
                )
                new_versions.append(f"{version}_{name}")

        conn.commit()

    print(f"Schema applied to: {DB_FILE}")
    if new_versions:
        print(f"New migrations recorded: {', '.join(new_versions)}")
    else:
        print("Schema is up to date.")


def query(
    sql: str,
    params: Optional[tuple] = None,
    output_json: bool = False,
) -> list[dict[str, Any]]:
    """Run a SQL query and return results.

    Args:
        sql: SQL query string.
        params: Optional tuple of query parameters.
        output_json: If True, output JSON format.

    Returns:
        List of row dictionaries.
    """
    if not DB_FILE.exists():
        raise FileNotFoundError(
            f"Database not found: {DB_FILE}\n"
            "Run 'python store.py init' to create it."
        )

    with get_connection() as conn:
        cursor = conn.cursor()
        try:
            if params:
                cursor.execute(sql, params)
            else:
                cursor.execute(sql)

            # Check if this is a SELECT query
            if cursor.description is None:
                conn.commit()
                print(f"Query executed. Rows affected: {cursor.rowcount}")
                return []

            rows = cursor.fetchall()
            results = [dict(row) for row in rows]

            if output_json:
                print(json.dumps(results, indent=2, default=str))
            else:
                _print_table(results, cursor.description)

            return results

        except sqlite3.Error as e:
            raise RuntimeError(f"SQL error: {e}") from e


def _print_table(rows: list[dict], description: tuple) -> None:
    """Print results as a human-readable table."""
    if not rows:
        print("No results.")
        return

    # Get column names
    columns = [col[0] for col in description]

    # Calculate column widths
    widths = {col: len(col) for col in columns}
    for row in rows:
        for col in columns:
            val = str(row.get(col, ""))
            # Truncate long values for display
            if len(val) > 50:
                val = val[:47] + "..."
            widths[col] = max(widths[col], len(val))

    # Print header
    header = " | ".join(col.ljust(widths[col]) for col in columns)
    separator = "-+-".join("-" * widths[col] for col in columns)
    print(header)
    print(separator)

    # Print rows
    for row in rows:
        line_parts = []
        for col in columns:
            val = str(row.get(col, ""))
            if len(val) > 50:
                val = val[:47] + "..."
            line_parts.append(val.ljust(widths[col]))
        print(" | ".join(line_parts))

    print(f"\n({len(rows)} rows)")


def main() -> None:
    """CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Database management for translation auditing.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python store.py init                    # Create database from schema
    python store.py init --force            # Recreate database
    python store.py migrate                 # Apply schema updates
    python store.py query "SELECT * FROM glossary"
    python store.py query --json "SELECT * FROM session_log"
        """,
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    # init subcommand
    init_parser = subparsers.add_parser(
        "init", help="Create database from schema.sql"
    )
    init_parser.add_argument(
        "--force",
        "-f",
        action="store_true",
        help="Delete existing database and recreate",
    )

    # migrate subcommand
    subparsers.add_parser(
        "migrate", help="Apply schema updates to existing database"
    )

    # query subcommand
    query_parser = subparsers.add_parser("query", help="Run a SQL query")
    query_parser.add_argument("sql", help="SQL query to execute")
    query_parser.add_argument(
        "--json", "-j", action="store_true", help="Output results as JSON"
    )

    args = parser.parse_args()

    try:
        if args.command == "init":
            init_database(force=args.force)
        elif args.command == "migrate":
            migrate_schema()
        elif args.command == "query":
            query(
                args.sql,
                output_json=args.json,
            )
    except FileNotFoundError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except RuntimeError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
